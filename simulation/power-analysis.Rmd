---
title: "Empirical power analysis"
author: "Matt Jaquiery (matt.jaquiery@psy.ox.ac.uk)"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
    # css: ../src/writeUp.css
    # includes:
      # after_body: ../src/toc_menu.html
editor_options:
  chunk_output_type: inline
---

April 2020

[Script run `r Sys.time()`]

# Feelings of Responsibility by Receivership of Reward
## Marwa El Zein and Matt Jaquiery

Peopleâ€™s sense of responsibility for decisions is strongly dependent on the success of the outcome. We want to know whether this effect is dependent upon whether the person concerned actually receives the outcome.

## Power analysis using simulations

The techniques used here are illustrated in the power-analysis-demo.Rmd file. The simulations in that demo gave us a rough indication of the landscape, and now we can target the exact cell we want and look at the power in that specific cell using many more simulation repetitions. We will be picking a *d* = 0.7 for all main effects because that seems reasonable based on prior research. 

### Structure

The task structure occurs in sets of 20 trials (1:1 ratios for minority/majority and no/reward, and 2:3 ratio for participant/other rewarded). There are three of these sets in a study. Below we use an example simulation of one study of one participant to demonstrate the trial structure:

```{r echo=T}
library(tidyverse)

source("generate-data.R")
allSD <- 7  # estimated SD of responses from everyone for scaling effect sizes
beneficiary <- .7 * allSD
majority <- .7 * allSD
effect <- .7 * allSD
n <- 1

# generate-data.R exports this function
generateData(n, beneficiary, beneficiary/3, majority, majority/3, effect, effect/3) %>%
  select(trialId:pInMajority) #%>% write.csv('tmp-data/structure.csv', row.names = F)

```

### Power analysis

First we define a function which will turn a simulation into two values: the ANOVA p-value and the Bayesian ANOVA BayesFactor. 

```{r echo=T}

# For simplicity we hardcode all the values here
sim <- function(r, printTo = NULL) {
  require(ez)
  require(BayesFactor)
  require(purrr)
  require(magrittr)
  require(dplyr)
  require(tidyr) # required by generateData
  require(tibble) # required by generateData
  
  allSD <- 7  # estimated SD of responses from everyone for scaling effect sizes
  beneficiary <- .7 * allSD
  majority <- .7 * allSD
  effect <- .7 * allSD
  n <- 50
  
  data <- generateData(n, beneficiary, beneficiary/3, majority, majority/3, effect, effect/3)
  suppressWarnings(
    aovs <- data %>%
      mutate_at(vars(pid, outcome, pGetsOutcome, pInMajority), factor) %>%
      nest(data = everything()) %>%
      mutate(
        aov = map(data, ~ ezANOVA(data = .x,
                                  dv = scaleResp_plain,
                                  wid = pid,
                                  within = c(
                                    outcome,
                                    pGetsOutcome,
                                    pInMajority
                                  ))),
        aovBF = map(data, ~ anovaBF(data = .x,
                                    formula = scaleResp_plain ~ 
                                      outcome + pGetsOutcome + pInMajority + pid,
                                    whichRandom = 'pid', progress = F))
      )
  )
  
  
  # fetch unique contribution of the outcome:pGetsOutcome interaction in anova and anovaBF
  f <- function(x) x$ANOVA %>% filter(Effect == 'outcome:pGetsOutcome') %>% .$p
  f.bf <- function(x) {
    x <- x@bayesFactor %>% 
      mutate(n = rownames(.)) 
    mdl <- x %>% filter(n == "outcome + pGetsOutcome + outcome:pGetsOutcome + pInMajority + pid")
    err <- x %>% filter(n == "outcome + pGetsOutcome + pInMajority + pid")
    # transitivity of bayesfactors means dividing mdl by err gives BF of mdl:err
    exp(mdl$bf - err$bf) # convert log-likelihood to likelihood
  }
  aovs <- aovs %>%
    mutate(
      p = map_dbl(aov, f),
      bf = map_dbl(aovBF, f.bf)
    )
  
  if (!is.null(printTo)) {
    out <- tribble(
      ~rep, ~p, ~bf,
      r, aovs$p, aovs$bf
    )
    write.table(out, printTo, sep = ",", append = T, col.names = F, row.names = F)
  }
  
  list(rep = r, p = aovs$p, bf = aovs$bf)
}

```

Then we set that to run in parallel for some number of repetitions.

```{r echo=T}
library(parallel)

reps <- 10000

# we actually run 100 x 100 reps to ensure we don't hit memory issues, etc, offloading to the hard drive as we go

outfile <- paste0(getwd(), '/tmp-data/reps.csv')
write.table(tribble(~rep, ~p, ~bf), outfile, sep = ",", append = F)

timeStart <- Sys.time()

for (r in 1:sqrt(reps)) {
  cl <- makeCluster(detectCores() - 4)
  
  clusterExport(cl, c("generateData", "outfile"))
  
  parSapply(cl, 1:sqrt(reps), sim, printTo = outfile)
  
  stopCluster(cl)
}

timeEnd <- Sys.time()

data <- read.csv(outfile)

print(paste0(
  "Data generation complete. Generated ",
  nrow(data), " rows in ",
  round(difftime(timeEnd, timeStart, units = "secs"), 2), "s."
))
```

Finally we print some results

```{r}
print(paste0("ANOVA p < .05 power: ", mean(data$p < .05, na.rm = T),
             "; mean p = ", round(mean(data$p, na.rm = T), 6)))
print(paste0("ANOVA BF > 3 power: ", mean(data$bf > 3, na.rm = T),
             "; mean BF = ", round(mean(data$bf, na.rm = T), 2)))
```

## Technical details  

```{r results = 'hold'}
cat(paste('Time stamp:', Sys.time(), '\n\n'))
cat('Runtime \n')
proc.time()
cat('\n')
sessionInfo()
```