---
title: "Pilot 3 Analysis"
author: "Matt Jaquiery"
date: "21/06/2020"
output: html_document
---

[Script run `r Sys.time()`]

```{r, include=F}
knitr::opts_chunk$set(echo = F)
```

```{r, include=F}
library(tidyverse)
library(ggridges)
library(ez)
library(BayesFactor)
library(papaja)

theme_set(theme_apa() + theme(
  panel.grid = element_blank(),
  legend.position = 'top',
  text = element_text(size = 16)
))

#' Compare models within a anovaBF output to get relative likelihood
#' @param x the BFBayesFactor object containing the results
#' @param comparisons list of pairs of values for the comparisons. Values can be row numbers or model strings.
#' @return data frame with columns M1, M2, BF(M1,M2)
marginalBF <- function(x, comparisons) {
  ns <- rownames(x@bayesFactor)
  getIndex <- function(i) if (i %in% ns) which(ns == i) else i
  bf <- function(a, b) exp(a - b)
  out <- NULL
  for (comp in comparisons) {
    if (length(comp) == 1) {
      a <- getIndex(comp[1])
      out <- rbind(out, data.frame(
        M1 = ns[a],
        M2 = x@denominator@longName,
        BF.M1.M2 = exp(x@bayesFactor$bf[a])
      ))
    } else {
      a <- getIndex(comp[1]); b <- getIndex(comp[2]);
      out <- rbind(out, data.frame(
        M1 = ns[a], 
        M2 = ns[b],
        BF.M1.M2 = bf(x@bayesFactor$bf[a], x@bayesFactor$bf[b])
      ))
    }
    
  }
  if (!is.null(names(comparisons)))
    rownames(out) <- names(comparisons)
  out
}
```

# Introduction

How we judge our responsibility and the responsibility of others for actions’ outcomes has important consequences in our society. 
It is tightly related to whether we get rewarded or blamed for the actions we make, which is crucial for the maintenance of a cooperative and fair society. 
Even in our everyday lives, correctly or wrongfully attributing responsibility to ourselves and others for seemingly non crucial actions, can have emotional and long-term consequences.

How people attribute responsibility to themselves in a group is subjective: They tend to attribute higher responsibility for positive as compared to negative outcomes. 
This is known as the self-serving bias, where people claim more credit for positive events, while they duck responsibility for negative events (Caine & Schlenker, 1979; Forsyth & Schlenker, 1977; Leary & Forsyth, 1987; Miller & Schlenker, 1985).
This bias however does not seem to be purely selfish: it also appears when people judge their group or another person’s responsibility (Palmeira et al., 2015; Taylor & Doria, 1981). 
For example, in the context of advising, people exhibit an ‘other-serving’ bias as they tend to credit more than blame an advisor (Palmeira et al., 2015). 

In individual contexts, the rewards naturally seem to belong to the person producing a positive or negative outcome. 
In a group decision however, the outcome may be shared or given to one group member. 
It has been established that responsibility underlies ownership: control and intent of an action, which are directly associated with responsibility attributions, also predict whether a person is perceived as the owner of an object (Palamar et al., 2012). 
If attributions of responsibility predict ownership, is the opposite true?
Here we would like to address 1) whether _Outcome ownership_ changes attributions of responsibility and 2) whether _Outcome ownership_ is necessary for the self-serving and/or other-serving bias to appear.  
We investigate this question in a group decision-making context, where only one member can receive the outcome in each round. 

Participants will perform an online task where they make collective decisions through majority votes, then one member of the group can receive either a _Reward_ or _No reward_. 
Finally they will rate the responsibility of the group members for the outcome. 
This paradigm will allow us to address both questions stated above: 

1. by investigating whether responsibility attribution increases for the _Outcome owner_, although the control over the outcome is exactly similar. 

2. By checking whether the self and other-serving bias of higher responsibility ratings for positive outcomes depend on _Outcome ownership_. 

In other words, we will answer the question: do people exhibit the same self-serving bias when judging the responsibility for an outcome that is attributed to another member of their group? 
Do they also still exhibit an ‘other-serving’ bias when judging the responsibility of another group member who did not receive the outcome?
We will also investigate (1b) whether self- and other-serving biases are of similar strength.

The study reported here is the third pilot study.
In this study, participants provided a rating of responsibility for themself and the two other players after the outcome on every trial.
For consistency with other studies in this series, we describe it as having a 2x2x2x2 factor structure, with all factors within-subjects:

* Whether the rated player is the _Outcome recipient_:  
    * _Outcome owner_ versus _Not outcome owner_  
* The _Outcome valence_:  
    * _Reward_ versus _No reward_  
* The _Vote status_ of the participant in the group decision process:  
    * _Participant in majority_ versus _Participant in minority_  
    * Although this factor is part of the design, the complexity added to the statistical analysis does not justify its inclusion, so it does not form part of the main statistical analysis.  
* Whether the _Responsibility judgement_ is made about:  
    * _Own responsibility_ versus _Another's responsibility_  

# Method

## Statistical analysis

The primary analysis technique is ANOVA (Bayesian and frequentist). 
Bayesian ANOVA results are obtained by taking the likelihood of a model with the effect of interest plus all simpler effects compared to an alternative containing only the simpler effects. 
For main effects, this is the model for the effect alone compared to the intercept-only model; for one-way interactions this is the main effects plus interaction-of-interest model compared to the main effects only model.

## Materials

Experiments were custom-written in HTML/CSS/JavaScript using the [jsPsych framework](https://www.jspsych.org/) and undertaken by participants over the internet using their own devices.
The experiment code was written by Marwa El Zein and Matt Jaquiery.

## Procedure

The entry point to the study is through recruitment on the Prolific (https://prolific.ac/) participant recruitment platform.
Participants accepting the study are forwarded to the experiment website, where they provide informed consent for participation before entering the main experiment page.
The experiment begins with detailed instruction pages which describe the structure of each round in the game, with screenshots of each stage, followed by a short training trial sequence.
Once they have read the instructions and familiarised themselves with the game, participants begin the main experiment, which consists of 3 blocks of 24 trials.
The 24 trials are a randomised sequence of balanced repetitions of each of the 12 unique trial types (as defined by whether the outcome is a reward/no reward; whether the participant is in the majority/minority; and which the player receives the outcome).
The a reward/no reward trials and the trials with the participant in the majority/minority occurred equally frequently, and each player receives the outcome on 1/3rd of all trials.
In trials where the participant is in the majority, one other player selects the same gamble as the participant and the other player selects a random gamble, meaning that on approximately half of these trials the vote is unanimous.

Each trial begins with a display of the three players.
This is followed by a screen in which the participant selects one of two gamble images.
Gamble images are selected from a collection of hand-drawn images of gambling devices and paraphernalia, and are counterbalanced such that each pair of images is shown the same number of times.
Which gamble is selected has no influence on the outcome of the trial, which is predetermined.
Once the participant selects a gamble the their player icon is shown on the gamble they chose.

If the participant has not selected a gamble by the end of the choice window, the rest of the trial is cancelled and the participant is shown a warning message which states that they have failed to make a choice in time.
If the participant did select a gamble, the player icons for the other players are shown on the gambles selected by the other players.
The gamble with two or more player icons is selected.
Next, the gamble is allocated to one of the players and its outcome is shown (a coin for a rewarded trial or a coin with a cross through it for an unrewarded trial).

Finally, the participant is asked to rate each player's responsibility for the outcome using a slider.
The responsibility rating phase lasts until all the responsibility ratings have been submitted.

Once all 72 experimental trials have been completed, participants are debriefed, thanked, and returned to Prolific.
Payment follows once all participants have completed the study and bonuses have been calculated.

## Open science

### Preregistration

Experiment 3 was [preregistered on the Open Science Framework platform (OSF)](https://osf.io/bgr94).
The analysis plan deviated from the preregistration in that participants are removed for using the same gamble choice response key on consecutive trials only if they used the same key for all trials in a block (after removing trials with no response).

### Open materials

Materials for the studies can be found on the [GitHub repository](https://github.com/mjaquiery/responsibility-by-reward/tree/35474eada0141838972fc86006c61f104a02e835/ATTRRESP) as it stood on 18th June 2020.

### Open data

Data for this pilot experiment are [available](https://raw.githubusercontent.com/mjaquiery/responsibility-by-reward/master/data/dataEXP3.csv) on GitHub in .csv format.

```{r read data}
fName <- '../data/dataEXP3.csv'
if (!file.exists(fName)) 
  fName <- str_replace(
    fName, 
    '../', 
    'https://raw.githubusercontent.com/mjaquiery/responsibility-by-reward/master/'
  )

d <- read.csv(fName, sep = ";", stringsAsFactors = F) %>% 
  as_tibble() 

# Remove testing data
d <- d %>% filter(prolificid != "", prolificid != "Matt")

# inject bloc into d. Really this should be recorded in JS!
d <- d %>% mutate(bloc = case_when(
  as.numeric(trial_index) < 12 ~ NA_integer_,
  as.numeric(trial_index) < 36 ~ 1L,
  as.numeric(trial_index) < 61 ~ 2L,
  as.numeric(trial_index) < 87 ~ 3L,
  T ~ NA_integer_
))

d

if (any(d$participant_id != 1, na.rm = T))
  stop("Some participants have the wrong id (should be 1). This must be corrected before this analysis will work correctly.")

```

### Exclusions

```{r descriptive stats}

d.old <- d

max_missed_trials <- 10
expected_trial_n <- 72 # 3 sets of 2x12 trials

# double_entry
exclude_ids <- d %>%
  nest(d = -prolificid) %>%
  mutate(
    d = map(d, ~ filter(., subject_id != subject_id[1]))
  ) %>%
  unnest(cols = d) %>%
  select(subject_id) %>% 
  unique() %>%
  mutate(double_entry = T)

# max_missed_trials
exclude_ids <- full_join(
  exclude_ids,
  d %>% 
    nest(df = -subject_id) %>%
    mutate(missed_trials = 
             map_dbl(df, . %>% filter(vote_p1 == "") %>% nrow()),
           missed_trials = missed_trials >= max_missed_trials) %>%
    filter(missed_trials) %>%
    select(-df),
  by = "subject_id"
)

# expected_trial_n
exclude_ids <- full_join(
  exclude_ids, 
  d %>%
    filter(label == 'scaleresp') %>%
    nest(df = -subject_id) %>%
    mutate(df = map_dbl(df, nrow)) %>%
    filter(df < expected_trial_n) %>%
    mutate(trial_count = T) %>%
    select(-df),
  by = "subject_id"
  )

# We now remove missed trials
# Whether we do this BEFORE or AFTER checking consecutive responses matters
d <- d %>% filter(vote_p1 != "")

# max_consec_resp
exclude_ids <- full_join(
  exclude_ids,
  d %>% 
    nest(d = c(-subject_id, -bloc)) %>%
    mutate(
      consec_resp = map_lgl(d, ~ all(.$vote_p1 == .$vote_p1[1]))
    ) %>%
    filter(consec_resp) %>%
    select(subject_id, consec_resp) %>%
    unique(),
  by = "subject_id"
)

exclude_ids %>% 
  mutate(total_unique_exclusions = 1) %>% 
  select(everything(), total_unique_exclusions, -subject_id) %>% 
  summarise_all(sum, na.rm = T) %>% 
  pivot_longer(cols = everything(), 
               names_to = 'Reason', 
               values_to = 'N excluded') %>%
  apa_table()

d <- d %>% 
  filter(!(subject_id %in% exclude_ids$subject_id)) %>% 
  mutate(
    subject_id = factor(subject_id),
    status = factor(status, labels = c('Participant in majority', 
                                       'Participant in minority')),
    outcome = factor(outcome, labels = c('Reward', 'No reward')),
    getsout = factor(getsout, labels = c('Player 0', 'Participant', 'Player 2')),
    pgetsout = factor(if_else(getsout == "Participant", 1, 2), labels = c(
      'Participant gets outcome', 'Another gets outcome'
    ))
  )

```

Before exclusion we have `r length(unique(d.old$subject_id))` subject_ids. We now exclude participants who have more than `r max_missed_trials` missed trials, only used one of the two response keys in a block,[^This exclusion criterion differs from its preregistered form because we inspected the data and judged that participants excluded using the preregistered rule were nevertheless contributing data which looked sensible. Results are highly similar when data are excluded according to the preregistration criterion.] or had fewer than `r expected_trial_n` trials recorded. 
Our final participant list contains `r length(unique(d$subject_id))` participants.

### Demographics 

```{r}

d %>% 
  transmute(unique_genders = str_to_upper(gender)) %>% 
  unique()

gender <- d %>% 
  select(prolificid, gender) %>% 
  mutate(gender = str_to_upper(gender)) %>% 
  unique()

age <- d %>% 
  select(prolificid, age) %>% 
  mutate(age = as.numeric(age)) %>%
  unique()

```

Participants self-reported a mean age of `r pull(age, age) %>% mean() %>% round(1)` (SD = `r pull(age, age) %>% sd() %>% round(1)`) years and their genders as M (`r gender %>% filter(gender == 'M') %>% nrow()`), F (`r gender %>% filter(gender == 'F') %>% nrow()`), or otherwise (`r gender %>% filter(gender != 'M' & gender != 'F') %>% nrow()`).

Data were collected on the following days:

```{r experiment dates, results = 'asis'}
d %>%
  select(subject_id, date) %>%
  unique() %>%
  group_by(date) %>%
  summarise(n = n(), .groups = 'drop') %>%
  rename(Date = date, Participants = n) %>%
  apa_table()

```

### Response times

```{r}
max_rt <- 30000
```

Participants make four responses on a trial, choosing a gamble and indicating how responsible each of the players was for the decision. 

```{r response time visualisations, fig.height=14, fig.width=6}

tmp <- d %>% 
  select(subject_id, time_choice_start, time_choice_made, starts_with('responsibility_time')) %>%
  pivot_longer(c(time_choice_made, starts_with('responsibility_time')),
               names_to = "Event", 
               values_to = "Time") %>%
  mutate(Time = Time - time_choice_start) %>%
  mutate(Event = case_when(
    str_detect(Event, 'responsibility_time') ~ str_extract(Event, 'p[0-9]+$'),
    T ~ Event)
  ) %>%
  filter(!is.na(Event) & !is.na(Time)) %>%
  rename(Participant = subject_id)

# Replace out-of-scale values with a count of dropped values
dropped <- tmp %>%
  group_by(Participant) %>%
  filter(Time > max_rt) %>%
  transmute(n = n())

tmp <- tmp %>% filter(Time <= max_rt)

ggplot(tmp, aes(y = Participant, x = Time, fill = Event, colour = Event)) +
  geom_vline(xintercept = 2000, linetype = 'dashed', colour = 'grey75') +
  geom_density_ridges(alpha = .25) +
  geom_point(position = position_jitter(0, .05), alpha = .25) +
  geom_text(aes(label = paste0('... +', dropped$n), y = Participant),
            inherit.aes = F, x = max_rt, colour = 'grey', data = dropped) +
  scale_x_continuous(limits = c(0, max_rt)) +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    legend.position = 'top'
  )

```


### Feeling of responsibility scale usage

```{r, fig.height=14, fig.width=6}

tmp <- d %>% 
  pivot_longer(starts_with('responsibility_rating_p'),
               names_to = 'rated_player',
               values_to = 'response') %>%
  mutate(rated_player = str_extract(rated_player, 'p[0-9]+$'),
         rated_player = if_else(rated_player == 'p1', 'Participant', rated_player)) %>%
  select(subject_id, response, rated_player) %>%
  nest(df = -subject_id) %>%
  mutate(sum = map_dbl(df, ~ sum(.$response))) %>%
  unnest(cols = df)
tmp$subject_id <- reorder(tmp$subject_id, tmp$sum)
  
ggplot(tmp, aes(x = response, y = factor(subject_id), 
                colour = rated_player, fill = rated_player)) +
  geom_density_ridges(alpha = .25) +
  scale_x_continuous(limits = c(0, 100)) +
  labs(y = 'Participant', x = 'Responsibility rating') +
  scale_colour_discrete(name = 'Rated player', aesthetics = c('colour', 'fill')) +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    legend.position = 'top'
  ) 

```

## Inferential statistics

Participants make one rating of responsibility for each of the three players (including themself) on each trial. 
These data are averaged in order to conduct ANOVA by organising each rating on each trial according to the following factors:

* ANOVA:  
    * _Outcome valence_: Whether the trial result is _Reward_ or _No reward_  
    * _Outcome recipient_: Whether the rated player is the _Outcome owner_ or _Not outcome owner_  
    * _Is participant_: Whether the rated player is the _Participant_ or _Another player_   

```{r}

#' GGplot2 helper function to get offset x coordinates to the left or right
#' depending on whether the x coordinate is to the left or right.
#' @param x vector of x coordinates (typically factors)
#' @param amount amount to nudge in the appropriate direction
#' @param direction to nudge. 'outwards' is towards the extremes, 'inwards' is towards the centre.
nudge <- function(x, amount, direction = 'outwards') {
  if (!is.factor(x))
    x <- factor(x)
  x <- as.numeric(x) 
  dir <- if (direction == 'outwards') 1 else -1
  x + sign(x - mean(range(x, na.rm = T))) * dir * amount
}


d.long <- d %>% 
  pivot_longer(cols = starts_with('responsibility_rating_p'),
               names_to = 'rated_player',
               values_to = 'responsibility_rating') %>%
  mutate(rated_player = str_extract(rated_player, 'p[0-9]+$'),
         rated_player = case_when(rated_player == 'p0' ~ 'Player 0', 
                                  rated_player == 'p1' ~ 'Participant',
                                  rated_player == 'p2' ~ 'Player 2'),
         is_participant = factor(if_else(rated_player == 'Participant',
                                         'ratingForParticipant',
                                         'ratingForOther')),
         gout = if_else(getsout == 'Participant', 
                        'Participant', as.character(getsout)),
         rated_gets_outcome = str_detect(rated_player, paste0(gout)),
         rated_gets_outcome = factor(if_else(rated_gets_outcome, 
                                             'ratedGetsOutcome',
                                             'otherGetsOutcome')),
         `Outcome recipient` = if_else(
           rated_gets_outcome == "ratedGetsOutcome",
           "Outcome owner", "Not outcome owner"
         ),
         `Outcome valence` = outcome)

```

```{r}
dw <- .25

d.long %>%
  group_by(subject_id, `Outcome valence`, `Outcome recipient`, is_participant) %>% 
  summarise(responsibility_rating = mean(responsibility_rating), .groups = 'drop') %>%
  mutate(
    `Is participant` = if_else(is_participant == "ratingForOther",
                             "...for Non-participant", 
                             "...for Participant")
  ) %>%
  ggplot(aes(x = `Outcome valence`, y = responsibility_rating, colour = `Outcome recipient`)) +
  geom_hline(yintercept = 100 / 3, linetype = 'dashed') +
  geom_point(alpha = .1, position = position_jitterdodge(dw/1.5, dodge.width = dw)) +
  stat_summary(geom = "point", aes(group = `Outcome recipient`), size = 4, 
               fun = mean, position = position_dodge(dw), shape = 0) +
  stat_summary(geom = "errorbar", aes(group = `Outcome recipient`), width = 0, 
               fun.data = mean_cl_normal, position = position_dodge(dw)) +
  stat_summary(geom = 'line', fun = mean, aes(group = `Outcome recipient`), 
               position = position_dodge(dw)) +
  scale_colour_discrete(h.start = 180) +
  facet_wrap(~`Is participant`) +
  labs(x = "Gamble outcome", 
       y = "Participant rating of responsibility...")

```

```{r}

suppressWarnings({
  a <- ezANOVA(
    data = d.long,
    dv = responsibility_rating,
    wid = subject_id,
    within = c(
      outcome,
      rated_gets_outcome,
      is_participant
    ),
    type = 3
  )
})

a %>%
  apa_table()

```

There main effects for _Outcome valence_, and _Outcome recipient_, but the effect of whether the rated player _Is the participant_ is non-significant.

For two-way interactions, there are interactions between _Outcome valence_ and _Outcome recipient_, between _Outcome valence_ and whether the rated player _Is the participant_, as well as between _Outcome recipient_ and whether the rated player _Is the participant_.

The three-way interaction between _Outcome valence_, _Outcome recipient_, and _Is participant_ was also significant.

### 1) Are players considered more responsible if they are the _Outcome owner_?

```{r effect of getting the outcome}
dw <- .075

tmp <- d.long %>% 
  group_by(subject_id, `Outcome recipient`) %>%
  summarise(responsibility_rating = mean(responsibility_rating), .groups = 'drop') 

tt <- t.test(
  x = tmp$responsibility_rating[tmp$`Outcome recipient` == 'Not outcome owner'],
  y = tmp$responsibility_rating[tmp$`Outcome recipient` != 'Not outcome owner'],
  paired = T
)

tt <- paste0(
  't(', tt$parameter, ') = ', round(tt$estimate, 2), '\n',
  'p < ', round(tt$p.value + 1e-3, 3)
)

ggplot(tmp, aes(x = `Outcome recipient`, y = responsibility_rating)) +
  geom_line(aes(group = subject_id), colour = 'grey') +
  geom_boxplot(outlier.colour = NA, width = dw,
               aes(x = nudge(`Outcome recipient`, dw),
                   group = `Outcome recipient`)) +
  geom_segment(x = 1 - dw, xend = 2 + dw, y = 110, yend = 110) +
  geom_label(x = 1.5, y = 110, label = tt) +
  scale_x_discrete(expand = c(0, dw * 4)) +
  scale_y_continuous(limits = c(0, 115), breaks = seq(0, 100, length.out = 5)) +
  labs(y = 'Rating of responsibility')

```

The figure shows participant mean responsibility ratings collapsed across other trial factors (lines) and their distributions (box plots).
Participants rate players' responsibility as higher when that player receives the outcome.

### 2) Does the self/other-serving bias, i.e, higher responsibility for positive _Outcome valence_, change if the rated player is _Not outcome owner_?

```{r interaction of outcome valence and getting the outcome}

tmp <- d.long %>% 
  group_by(subject_id, `Outcome recipient`, `Outcome valence`) %>%
  summarise(responsibility_rating = mean(responsibility_rating), 
            .groups = 'drop')

tt <- tmp %>%
  nest(d = -`Outcome recipient`) %>%
  mutate(
    tt = map(d, ~ t.test(
      x = .$responsibility_rating[.$`Outcome valence` == 'No reward'],
      y = .$responsibility_rating[.$`Outcome valence` != 'No reward'],
      paired = T
    )),
    tt = map_chr(tt, ~ paste0(
      't(', .$parameter, ') = ', round(.$estimate, 2), '\n',
      'p < ', round(.$p.value + 1e-3, 3)
      ))
  ) %>%
  select(-d)

ggplot(tmp, aes(x = `Outcome valence`, y = responsibility_rating)) +
  geom_line(aes(group = subject_id), colour = "grey") +
  geom_boxplot(outlier.colour = NA, width = dw,
               aes(x = nudge(`Outcome valence`, dw),
                   group = `Outcome valence`)) +
  geom_segment(x = 1 - dw, xend = 2 + dw, y = 110, yend = 110) +
  geom_label(aes(label = tt), x = 1.5, y = 110, data = tt) +
  scale_x_discrete(expand = c(0, dw * 4)) +
  scale_y_continuous(limits = c(0, 115), breaks = seq(0, 100, length.out = 5)) +
  labs(y = 'Rating of responsibility') +
  facet_wrap(~paste0('When ', `Outcome recipient`))

```

The figure shows participant mean responsibility ratings collapsed across other trial factors (lines) and their distributions (box plots).
The 'self/other-serving bias' is evident on trials where the rated player gets the outcome, but not where another player gets the outcome. 

# Interpretation

Players are considered more responsible if they get the outcome than otherwise.
The bias towards greater responsibility ratings for Reward as opposed to No reward outcomes appears to be largely confined to the player receiving the outcome.
This self/other-serving bias is more pronounced as a self-serving bias than an other-serving bias.

Bayesian stats in this complex setup are difficult to do correctly such that they give reliable and defensible results, and the results are consistent across similar statistical analyses (see below). 
The frequentist tests are used for the power analysis and will be used for the main experiments.

# Additional analyses

### Effect size estimation

The effect size (and variance) is estimated for the power analysis. 

```{r}

es <- d.long %>%
  nest(data = -subject_id) %>%
  mutate(
    data = map(data, ~ mutate(., rr.z = scale(responsibility_rating))),
    m = map(
      data, 
      ~ lm(rr.z ~ rated_gets_outcome * outcome * is_participant, data = .)
    ),
    coefs = map(m, broom::tidy)
  ) %>% 
  unnest(cols = coefs)

es %>% 
  # filter(term == "rated_gets_outcomeTRUE:outcomeTRUE:is_participantTRUE") %>%
  mutate(
    term = str_replace_all(
      term, c(
        'outcomeNo reward' = 'NoRw',
        'rated_gets_outcomeratedGetsOutcome' = 'GetsOut',
        'is_participantratingForParticipant' = 'IsPar'
      ))
  ) %>%
  ggplot(aes(x = term, y = estimate, colour = p.value < .05)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  geom_point(position = position_jitter(width = .1)) +
  stat_summary(geom = "point", fun = mean, shape = 19, size = 2, colour = 'black') +
  stat_summary(geom = "errorbar", fun.data = mean_cl_normal, width = 0, colour = 'black') +
  theme(
    axis.text.x = element_text(angle = 25, hjust = 1)
  )

v <- es %>% 
  filter(term == "rated_gets_outcomeratedGetsOutcome:outcomeNo reward:is_participantratingForParticipant") %>%
  pull(estimate) 

t.test(v, mu = 0)
paste0('Mean = ', mean(v))
paste0('SD = ', sd(v))

```

### Vote status factor

We also examine the ANOVA results where _Vote status_ is considered as a factor. 
Previous experiments have shown that this can matter. 
Theoretically, this can be important because a player who is outvoted might be seen as less responsible for an outcome.
Generally, however, this factor is orthogonal to our questions: players are outvoted as often as they are part of the winning vote.
Note that this factor is encoded only with respect to the participant (we doubt whether participants can remember which players did or did not vote for which outcomes in this design).

* ANOVA:  
    * _Outcome valence_: Whether the trial result is _Reward_ or _No reward_  
    * _Outcome recipient_: Whether the rated player is the _Outcome owner_ or _Not outcome owner_  
    * _Is participant_: Whether the rated player is the _Participant_ or _Another player_  
    * _Vote status_: Whether the _Participant is in the majority_ or _minority_ in the gamble choice  

```{r}

suppressWarnings({
  a.full <- ezANOVA(
    data = d.long,
    dv = responsibility_rating,
    wid = subject_id,
    within = c(
      outcome,
      rated_gets_outcome,
      status,
      is_participant
    )
  )
})

a.full %>%
  apa_table()

```

The Bayesian statistics take a long time to run and this analysis is only of secondary interest, so they are not included here. 
With the additional factor of status (for which the main effect is significant), the effects previously seen in the model remain, including the three-way interaction between _Outcome valence_, _Outcome recipient_, and _Vote status_.
Additionally, status forms significant two-way interactions with all the other variables except _Outcome valence_.
There is a three-way interaction of _Vote status_ with the Self/Other-serving bias effect (_Outcome valence_ and _Outcome recipient_), but not with the other variable pairs. 
The four-way interaction is not significant. 
This analysis suggests that controlling for participant vote status is not vital to obtaining answers about the performance of participants in this experiment.

### Bayesian analyses (dropped)

Bayesian statistics were dropped from this point onwards because multiple different model comparison approaches yielded results which were very difficult to reconcile. 
The analysis which is equivalent to that used in pilots 1 and 2 is a model comparison approach where (e.g.) the main effects are tested with a main-effects-only model compared to a model with the target main effect missing.
There are other approaches, such as comparing a model with only the effect of interest to the intercept-only model (bottom-up) and comparing the full model (with all effects) to a model with effect of interest removed (top-down).
These approaches give different interpretations of the effects, as shown below.

#### Peer model comparison

In the peer model comparison the effects are determined based on the relative likelihoods of two models.
The specifics of which models are compared differ for main effects and interactions.  

* Main effects are determined by taking a model with all main effects and comparing it to a model with the main effect of interest removed.  

* Interactions are determined by taking a model with the interaction and comparing it to a model with the main effects and all simpler interactions (no interactions for 2-way interactions, all 2-way interactions for the 3-way interaction).

In all model comparison cases, if the model containing the effect of interest is more likely than the model which does not contain that effect, this is taken as evidence of the effect's explanatory power. 
If the model with the effect is 3 or more times as likely given the evidence, this is taken as signifying that the effect is significant.
If the model without the effect is 3 or more times as likely, this is taken as signifying the effect is demonstrably non-significant.

```{r}

a.bf = anovaBF(
  data = as.data.frame(d.long),
  formula = responsibility_rating ~ 
    outcome + rated_gets_outcome + is_participant + subject_id,
  whichRandom = 'subject_id', progress = F
)
a.bf %>% 
  marginalBF(comparisons = list(
    # 1, 2, 5, # Main effect vs random effects model
    c(8, 7), c(8, 6), c(8, 3), # Main effects vs model with other main effects
    c(9, 8), c(11, 8), c(14, 8), # 2-way interactions vs main effects model
    c(18, 17)# 3-way interactions vs 2-way interactions model
  )) %>%
  mutate(` ` = case_when(BF.M1.M2 < 1/3 ~ '-', 
                         BF.M1.M2 > 3 ~ '+', 
                         T ~ '')) %>%
  apa_table()

```

#### Top-down

The top-down approach compares the full model with all effects to a model with the effect of interest removed.

```{r}

a.bf.td = anovaBF(
  data = as.data.frame(d.long),
  formula = responsibility_rating ~ 
    outcome * rated_gets_outcome * is_participant * subject_id,
  whichRandom = 'subject_id', progress = F, whichModels = 'top'
)

a.bf.td

plot(a.bf.td)
```

#### Bottom-up

The bottom-up approach compares the model with the effect of interest plus the intercept to the intercept-only model.

```{r}

a.bf.bu = anovaBF(
  data = as.data.frame(d.long),
  formula = responsibility_rating ~ 
    outcome * rated_gets_outcome * is_participant * subject_id,
  whichRandom = 'subject_id', progress = F, whichModels = 'bottom'
)

a.bf.bu

plot(a.bf.bu)
```

#### Comparison

While the main effects are present and the three-way interaction not present in all three model comparison approaches, the two-way interactions give different results on different comparison approaches. 
This instability, as well as the incompatibility with the effect of `is_participant` in the frequentist ANOVA, means that we have decided not to use the Bayesian ANOVA as a key outcome of interest in the main study.

# References 

Bruce T. Caine  and  Barry  R.  Schlenker. Role  Position and  Group  Performance  as  Determinants  of  Egotistical  Perceptions  in  Cooperative  Groups. The  Journal of  Psychology,   101(2):149–156,   March  1979. ISSN0022-3980. doi: 10.1080/00223980.1979.9915066. URL https://doi.org/10.1080/00223980.1979.9915066.

John  M.  Darley  and  Bibb  Latane.  Bystander  intervention in emergencies:  Diffusion of responsibility. Journal of Personality and Social Psychology, 8(4, Pt.1):377–383,1968. ISSN  1939-1315(Electronic), 0022-3514(Print). doi: 10.1037/h0025589.

Donelson R. Forsyth, Linda E. Zyzniewski, and Cheryl A. Giammanco. Responsibility   Diffusion   in   Cooperative   Collectives. Personality   and   Social   PsychologyBulletin,   28(1):54–65,   January   2002. ISSN   0146-1672. doi:10.1177/0146167202281005.URL https://doi.org/10.1177/0146167202281005.

Donelson   R.   Forsyth   and   Barry   R.   Schlenker. Attributing  the  causes  of  group  performance:   Effects  of performance  quality,  task  importance,  and  future  testing. Journal   of   Personality,   45(2):220–236,   1977. ISSN   1467-6494(Electronic), 0022-3506(Print). doi:10.1111/j.1467-6494.1977.tb00148.x.

Mark R. Leary and Donelson R. Forsyth.   Attributions of responsibility for collective endeavors. In Group processes, Review of personality and social psychology, Vol. 8., pages167–188. Sage Publications, Inc, Thousand Oaks, CA, US,1987. ISBN 978-0-8039-3071-1 978-0-8039-3072-8.

Rowland   S.   Miller   and   Barry   R.   Schlenker. Egotism   in   Group   Members: Public   and   Private   Attributions    of    Responsibility    for    Group    Performance. Social Psychology Quarterly, 48(1):85–89,1985. ISSN   0190-2725.doi:10.2307/3033785. URL https://www.jstor.org/stable/3033785.

Mauricio   Palmeira,    Gerri   Spassova,    and   Hean   TatKeh. Other-serving   bias   in   advice-taking: When advisors   receive   more   credit   than   blame. Organizational Behavior and Human Decision Processes,   130:13–25,   September   2015. ISSN   0749-5978.doi:10.1016/j.obhdp.2015.06.001. URL http://www.sciencedirect.com/science/article/pii/S0749597815000692.

Max  Rollwage,  Franziska  Pannach,  Caedyn  Stinson,  Ulf Toelch, Igor Kagan, and Arezoo Pooresmaeili.  Judgments of effort exerted by others are influenced by received rewards. Scientific Reports, 10(1):1–14, February 2020. ISSN 2045-2322.    doi:   10.1038/s41598-020-58686-0.    URLhttps://www.nature.com/articles/s41598-020-58686-0.

Donald  M.  Taylor  and  Janet  R.  Doria. Self-Serving and  Group-Serving  Bias  in  Attribution. The  Journal  of Social  Psychology,  113(2):201–211,  April  1981. ISSN0022-4545. doi: 10.1080/00224545.1981.9924371. URL https://doi.org/10.1080/00224545.1981.9924371. Publisher: Routledge_eprint: https://doi.org/10.1080/00224545.1981.9924371.

# Credits 

<!-- ## Acknowledgements -->

## R Packages

```{r R packages, results = 'asis'}
# list packages
packageNames <- (.packages())
# don't include very core package
packageNames <- packageNames[!(packageNames %in% 
                                 rownames(installed.packages(
                                   priority = "base")))]
# but do include the base package
packageNames <- c("base", packageNames)
out <- NULL
for (p in packageNames) {
  out <- rbind(out, data.frame('Package' = p, 
                               'Citations' = paste(format(citation(p), 
                                                          style = 'textVersion'), 
                                                   collapse = '<br/><br/>')))
}

out %>% apa_table()
```

## Funding

Marwa El Zein is a Sir Henry Wellcome Postdoctoral Fellow at University College London, funded by The Wellcome Trust (grant number 204702).

Matt Jaquiery is funded by a studentship from the [Medical Research Council](https://mrc.ukri.org/) (reference 1943590) and the University of Oxford [Department of Experimental Psychology](https://www.psy.ox.ac.uk/) (reference 17/18_MSD_661552).

<hr/>

## Technical details  

```{r technical details, results = 'hold'}
cat(paste('Time stamp:', Sys.time(), '\n\n'))
cat('Runtime \n')
proc.time()
cat('\n')
sessionInfo()
```